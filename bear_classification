!pip install --quiet fastdownload # this is for using helper function --> download_url 
from fastai.vision.all import *
import os
from fastdownload import download_url
pip install duckduckgo-search
!pip install --quiet --upgrade duckduckgo_search

ims = ['https://d3d0lqu00lnqvz.cloudfront.net/media/media/897b2e5d-6d4c-40fa-bbe8-6829455747e2.jpg']

dest = 'images/grizzly.jpg'
download_url(ims[0], dest)

im = Image.open(dest)
im.to_thumb(128,128)

bear_types = 'grizzly', 'black', 'teddy'
path = Path('bears')

if not path.exists():
    path.mkdir()
    for o in bear_types:
        dest = (path/o)
        dest.mkdir(exist_ok=True)
#####################################################################################
from duckduckgo_search import DDGS
from fastdownload         import download_url
from pathlib              import Path
import concurrent.futures

# 1) your categories
bear_types = ['grizzly','polar','black']  

# 2) base folder
base = Path('images')
base.mkdir(exist_ok=True)

# 3) helper to download a list of URLs into a folder
def download_images(urls, dest_folder, max_workers=8):
    def _dl(u):
        # sanitize a filename
        fname = u.split('/')[-1].split('?')[0]
        try:  download_url(u, dest_folder/fname)
        except: pass
    with concurrent.futures.ThreadPoolExecutor(max_workers) as ex:
        ex.map(_dl, urls)

# 4) loop with DDGS
with DDGS() as ddgs:
    for b in bear_types:
        dest = base/b
        dest.mkdir(exist_ok=True)
        # search
        results = ddgs.images(f'{b} bear', max_results=50)
        urls    = [r['image'] for r in results]
        # download
        download_images(urls, dest)
        print(f"{b:8} → {len(list(dest.iterdir()))} images downloaded")

fns = get_image_files(base)
fns


print(base, "contains →", (base.ls()))


